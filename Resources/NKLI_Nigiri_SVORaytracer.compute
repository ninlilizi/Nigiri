#pragma kernel PathTrace_uniform_grid

#include "UnityCG.cginc"
//#include "Utils.cginc"
//#include "NKLI_Nigiri_SVONode.cginc"
#include "SVO_Trace_DD.cginc"
RWTexture2D<float4> output;

Texture2D<float4> _CameraDepthTexture;
Texture2D<float4> _Lighting;
Texture2D<float4> _CameraGBufferTexture0;
Texture2D<float4> _CameraGBufferTexture1;
Texture2D<float4> _CameraGBufferTexture2;
Texture2D<float4> _CameraDepthNormalsTexture;


float4x4 _CameraToWorld;
float4x4 _CameraInverseProjection;
// SVO

uniform float3					sunLight;

//uniform half4					sunColor;
uniform float					sunLightInjection = 2;
uniform	float					GIGain = 2;

uniform sampler2D 				_MainTex;
uniform float					indirectLightingStrength = 2;


//camera data
float4x4 worldspace_frustum_corners;
float4 screen_size;
float4 camera_position;
float4 camera_normal;

int start_seed;

struct CS_INPUT
{
    uint3 Gid : SV_GroupID;
    uint3 GTid : SV_GroupThreadID;
    uint3 DTid : SV_DispatchThreadID;
    uint GI : SV_GroupIndex;
};


Ray CreateCameraRay(float2 uv)
{
    // Transform the camera origin to world space
    float3 origin = mul(_CameraToWorld, float4(0.0f, 0.0f, 0.0f, 1.0f)).xyz;
    
    // Invert the perspective projection of the view-space position
    float3 direction = mul(_CameraInverseProjection, float4(uv, 0.0f, 1.0f)).xyz;
    // Transform the direction from camera to world space and normalize
    direction = mul(_CameraToWorld, float4(direction, 0.0f)).xyz;
    direction = normalize(direction);

    return MakeRay(origin, direction);
}




uniform half3					sunColor;
uniform half3					skyColor;


//This is UV coords
float2 _Pixel;
//Cone directions https://github.com/turanszkij/WickedEngine/blob/master/WickedEngine/voxelConeTracingHF.hlsli
static const float3 CONES[] = 
{
    float3(0.57735, 0.57735, 0.57735),
    float3(0.57735, -0.57735, -0.57735),
    float3(-0.57735, 0.57735, -0.57735),
    float3(-0.57735, -0.57735, 0.57735),
    float3(-0.903007, -0.182696, -0.388844),
    float3(-0.903007, 0.182696, 0.388844),
    float3(0.903007, -0.182696, 0.388844),
    float3(0.903007, 0.182696, -0.388844),
    float3(-0.388844, -0.903007, -0.182696),
    float3(0.388844, -0.903007, 0.182696),
    float3(0.388844, 0.903007, -0.182696),
    float3(-0.388844, 0.903007, 0.182696),
    float3(-0.182696, -0.388844, -0.903007),
    float3(0.182696, 0.388844, -0.903007),
    float3(-0.182696, 0.388844, 0.903007),
    float3(0.182696, -0.388844, 0.903007)
};

//Alt directions

float3 CONESALT[] = {
    float3 (0,1,0),
    float3 (0,0.5,0.866025),
    float3 (0.822639,0.5,0.267617),
    float3 (0.509037,0.5,-0.700639),
    float3 (-0.509037,0.5,-0.700639),
    float3 (-0.822639,0.5,-0.267617)
};

//Not using
float weights[] = {
    PI/4, 3*PI/20,3*PI/20,3*PI/20,3*PI/20,3*PI/20
};



// Traces a ray starting from the current voxel in the reflected ray direction and accumulates color Using in reflection.
float4 RayTrace(float3 worldPosition, float3 reflectedRayDirection, float3 pixelNormal, float rayDist)
{
    // Color for storing all the samples
    float4 accumulatedColor = float4(.0f, .0f, .0f, .0f);

    float3 currentPosition = worldPosition + (0.15f * pixelNormal);
    float4 currentVoxelInfo = float4(0.0f, 0.0f,0.0f, 0.0f);

    bool hitFound = false;
    float rayStep = 0.125;
    //float dist;
    float currentWeight = 1.0;

    float totalWeight = 0.0;

    // Loop for tracing the ray through the scene
    for (float i = 0.0f; i < rayDist; i += rayStep)
    {
        //rayStep*= 1.5f;
        //dist += rayStep;
        // Traverse the ray in the reflected direction
        currentPosition += (reflectedRayDirection * rayStep);

        // Get the currently hit voxel's information
        currentVoxelInfo = GetVoxelInfoSVO(currentPosition, 0);

        // At the currently traced sample
        if (((int)currentVoxelInfo.a | 0) && (!hitFound))
        {
            accumulatedColor += currentVoxelInfo;
            // totalWeight += currentWeight;
            //hitFound = true; // We dont do this or fails to reflect!
            //break;
        }



    }
    // accumulatedColor /= totalWeight;

    return accumulatedColor;
}


float3 ComputeReflection(Ray ray, float skyVisibility, float3 pixelColor)
{
    ///Reflection cone setup
    float depthValue;
    float3 viewSpaceNormal;
    DecodeDepthNormal(_CameraDepthNormalsTexture[_Pixel], depthValue, viewSpaceNormal);
    //float lindepth =  LinearEyeDepth(depthValue);

    
    viewSpaceNormal = normalize(viewSpaceNormal);
    float3 pixelNormal = mul((float3x3)_CameraToWorld, viewSpaceNormal);
    float3 pixelToCameraUnitVector = normalize(camera_position - ray.origin);
    float3 reflectedRayDirection = reflect(pixelToCameraUnitVector, pixelNormal);
    reflectedRayDirection *= -1.0;
    float4 reflection = (0).xxxx;

    float3 viewVector = normalize(camera_normal);

    float4 spec = _CameraGBufferTexture1[_Pixel];

    float3 fresnel = pow(saturate(dot(viewVector.xyz,reflectedRayDirection)) * (spec.a * 0.5 + 0.5), 5.0);
    // fresnel = lerp(fresnel,spec.rgb, spec.a);
    // fresnel *= saturate(spec.a);

    fresnel = lerp(fresnel, (1.0).xxx, spec.rgb);
    fresnel *= saturate(spec.a );
    //if(spec.a>0)
    reflection = RayTrace(ray.origin, reflectedRayDirection, pixelNormal, 25) * 1 / 12;
    
    reflection.rgb = reflection.rgb * 0.7 + (reflection.a * 1.00 * float3(.1,.1,.1)) * 2.41 * 1 * skyVisibility;
    reflection *= float4(fresnel.rgb,1);

    return float4(max(0, reflection.rgb), saturate(reflection.a));
}


//WIP conetracing of scene.
float4 ConeTrace( Ray ray, float3 worldNormal, float3 pixelColor, float coneAperture)
{
    float4 computedColor = 0;
    float lengthOfCone = 1.0f;

    float maximumIterations = 64.0f;
    float coneStep = lengthOfCone / 8.00;
    float3 coneOrigin = ray.origin + (0.15f* worldNormal);
    float3 currentPosition = coneOrigin;
    float4 currentVoxelInfo = float4(0.0f, 0.0f, 0.0f, 0.0f);
    float hitFound = 0.0f;
    int coordSet = 0;
    float skyVisibility = 1.0f;
    float occlusion;
    float4 gi = (0).xxxx;
    currentPosition = coneOrigin;
    float3 voxelPosition = (0).xxx;

    float currentStep = 0;

    float4 currentColor;
    float alpha = 0;
    float dist = 0.25f; 

    
    while (dist < maximumIterations && alpha < 1)
    {
        float diameter =  2 * coneAperture * dist;
        float mip = log2(diameter /4);
        currentPosition += (coneStep * ray.direction);

        float fi = ((float)dist) / maximumIterations;
        fi = lerp(fi, 1.0, 0.0);

        float coneDistance = (exp2(fi * 4.0) - 0.99) / 8.0;
        float coneSize = coneDistance * 63.6;

        if (hitFound < 0.9f)
        {
            currentVoxelInfo = GetVoxelInfoSVO(currentPosition, 0);

            //Reverse blend.
            float a = 1- alpha;
            currentColor += currentVoxelInfo*float4(pixelColor,1) *a * fi;

            alpha += a *currentVoxelInfo.a;

            dist += diameter * coneStep;

        }
        occlusion = skyVisibility * skyVisibility;

        float falloffFix = pow(fi, 1.0) * 4.0 + 1;

        currentColor.a *= lerp(saturate(coneSize / 1.0), 1.0, 0.5f);
        currentColor.a *= (0.8 / (fi * fi * 2.0 + 0.15));
        
        gi.rgb += currentColor.rgb * occlusion * (coneDistance + 1) * 80.0 / falloffFix * (1.0 - fi * fi);// / falloffFix;

        skyVisibility *= pow(saturate(1.0 - currentColor.a * 0.0015f * (1.0 + coneDistance)), 0.65f);
    }
    if(currentVoxelInfo.a<1){
        gi = (0).xxxx;;
    }
    computedColor =  gi;
    //skyVisibility = 1;
    float NdotL = pow(saturate(dot(ray.direction, worldNormal) * 1.0 - 0.0), 0.5);

    computedColor *= NdotL;
    skyVisibility *= NdotL;
    skyVisibility *= lerp(saturate(dot(worldNormal, float3(0.0, 1.0, 0.0)) * 10.0 + 0.0), 1.0,1);
    float3 skyColor2 = float3(1.0f, 1.0f,1.0f);
    float3 sunColor2 = float3(256 / 124, 256 / 122, 256 / 118);

    float upGradient = saturate(dot(worldNormal, float3(0.0, 1.0, 0.0)));
    float sunGradient = saturate(dot(worldNormal, -sunLight.xyz));
    skyColor2 += lerp(skyColor2.rgb * 1.0, skyColor2.rgb * 0.5, pow(upGradient, (0.5).xxx));
    skyColor2 += sunColor2.rgb * pow(sunGradient, (4.0).xxx) * 1;

    computedColor.rgb *= 1 * 0.35f;
    computedColor.rgb += (skyColor * skyVisibility);
    
    return computedColor;
}


inline float3 ComputeIndirectContribution(Ray ray, float3 worldNormal, float3 pixelColor)
{
    float coneAperture = tan(PI * 0.5f * 0.33f);

    float3 color = (0).xxx;
    float3 origin = ray.origin;
    for (float i = 0.0f; i <16; i += 1)
    {
        
        float3 coneDirection = reflect(worldNormal,CONES[i]);
        //float3 coneDirection = normalize(CONES[i] + worldNormal);
        coneDirection *= dot(coneDirection,worldNormal) < 0 ? -1 : 1;
        ray.direction = coneDirection;
        
        color += ConeTrace(ray,worldNormal, pixelColor, coneAperture);
    }
    //color/= 8;
    return max(0, color);
}


//Lighting calcs
float4 lighting(Ray ray, float3 worldPos){
    
    float3 worldSpaceNormal = normalize(_CameraGBufferTexture2[_Pixel]*2-1);

    float3 rayPos;
    float3 directLightingSP = _Lighting[_Pixel];
    float4 pixelColor = _CameraGBufferTexture0[_Pixel];
    float4 metallic = _CameraGBufferTexture1[_Pixel];
    ray.direction = worldSpaceNormal;
    ray.origin = worldPos + 0.133f*ray.direction;
    
    float skyVisibility = 1;


    float3 indirectContribution = ComputeIndirectContribution(ray, worldSpaceNormal, pixelColor);
    float3 indirectLighting = directLightingSP + ((pixelColor.a * 1 * (1.0f - metallic.a) * pixelColor.rgb) / PI) * indirectContribution;


    //Reflections Calcs
    float3 reflection = ComputeReflection(ray, skyVisibility, directLightingSP);
    //if(metallic.a>0)
    reflection.rgb = lerp(indirectLighting.rgb, reflection.rgb, metallic.a);
    //else reflection = indirectLighting;
    // float3 metalshow = (metallic.r).xxx;
    return float4(reflection,1);
}


static const int NUM_BOUNCES =8;

[numthreads(16, 16, 1)]
void PathTrace_uniform_grid(CS_INPUT input)
{
    if (input.DTid.x <= screen_size.x && input.DTid.y <= screen_size.y)
    {
        _Pixel = input.DTid.xy;
        float depth = LinearEyeDepth ( DecodeFloatRG( _CameraDepthTexture[_Pixel]));

        
        //compute view ray
        //float2 uv = float2(input.DTid.xy) / (screen_size.xy - 1);
        float2 uv2 = float2((input.DTid.xy) / screen_size.xy * 2.0f - 1.0f);

        //V1
        // float3 eye_dir = lerp(lerp(worldspace_frustum_corners[0], worldspace_frustum_corners[1], uv.y), lerp(worldspace_frustum_corners[2], worldspace_frustum_corners[3], uv.y), uv.x);
        // eye_dir = normalize(eye_dir);
        
        // Invert the perspective projection of the view-space position
        float3 direction = mul(_CameraInverseProjection, float4(uv2, 0.0f, 1.0f)).xyz;
        // Transform the direction from camera to world space and normalize
        direction = mul(_CameraToWorld, float4(direction, 0.0f)).xyz;
        direction = (direction);

        //World position from depth
        float3 wPos = camera_position+ depth*direction;

        Ray ray = MakeRay(camera_position, direction);
        
        float3 L = SimpleGradient(ray);
        float4 hitColor;
        RayHit hit;

        hitColor = lighting(ray, wPos);
        //As we are not booling a hit we do this for now.
        if(hitColor.a>0.0f){
            L=hitColor;
        }     
        
        

        float4 ris = output[input.DTid.xy];
        ris = float4(L, 1 );
        output[input.DTid.xy] = ris;
    }
}